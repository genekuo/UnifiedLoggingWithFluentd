# This configuration for Chapter 5 to illustrate the use of the tag can control routing
# set Fluentd's configuration parameters
<system>
    Log_Level info
</system>

#### begin - tail basic file
<source>
  @type tail
  path ./Chapter5/basic-file.txt
  read_lines_limit 5
  tag basicFile
  pos_file ./Chapter5/basic-file-read.pos_file
  read_from_head true
  <parse>
    @type none
  </parse>
  @label labelPipeline
</source>
#### end - monitor_agent 1

#### begin - tail basic-file2
<source>
  @type tail
  path ./Chapter5/basic-file2.txt
  read_lines_limit 5
  tag basicFILE2
  pos_file ./Chapter5/basic-file-read2.pos_file
  read_from_head true
  <parse>
    @type json
  </parse>
  @label common
</source>
#### end - tail basic-file2

<label labelPipeline>

  #### use the stdout filter - to illustrate multiple steps within a label
  <filter *>
    @type stdout
  </filter>

  #### begin - file out 1 
  <match *>
    @type copy
    <store>
      ## as we're using a label to establish the pipeline then we can wild card the match
      @type file
      path ./Chapter5/label-pipeline-file-output
      <buffer>
        delayed_commit_timeout 10
        flush_at_shutdown true
        chunk_limit_records 50
        flush_interval 15
        flush_mode interval
      </buffer>
      <format>
        @type out_file
        delimiter comma
        output_tag true
      </format> 
    </store>
    <store>
      @type relabel
      @label common
    </store>
  </match>
  #### end - file out 1

</label>
#### end label - labelPipeline

#### begin - file out 2 - for log events with the tag basicFILE2
<label common>
  <match *>
      @type file
      path ./Chapter5/nonlabel-file-output
      <buffer>
        delayed_commit_timeout 10
        flush_at_shutdown true
        chunk_limit_records 50
        flush_interval 5
        flush_mode interval
      </buffer>
      <format>
        @type out_file
        delimiter comma
        output_tag true
      </format>    
  </match>
  #### end - file out 2
</label>